{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP6 : Reconnaissance d'image par un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na-Yck4lZiN1"
   },
   "source": [
    "### Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1606831889555,
     "user": {
      "displayName": "Stephan Semirat",
      "photoUrl": "",
      "userId": "06413469689434144964"
     },
     "user_tz": -60
    },
    "id": "Zupdaax6Xf8b"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  Y\n",
       "0   0   0   0   1   1   1   1   1   1  0\n",
       "1   0   0   1   0   0   1   0   0   0  0\n",
       "2   1   0   0   1   0   1   1   1   0  0\n",
       "3   1   1   0   1   1   1   0   0   1  1\n",
       "4   1   0   0   1   1   1   0   1   1  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture des données\n",
    "DIAGONAL=pd.read_csv(\"deuxdiag.csv\")\n",
    "# Visualisation des 5 premières données\n",
    "DIAGONAL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "1. Dans le jeu de données `DIAGONAL`, à quoi correspond une donnée ?\n",
    "2. On considère les données `X1`, ..., `X9` comme les 9 cases d'un carré 3*3 :<br/>\n",
    "    X1 X2 X3<br/>\n",
    "    X4 X5 X6<br/>\n",
    "    X7 X8 X9<br/>\n",
    "    À quelle condition sur les `Xi` a-t-on : une des deux diagonales du carré est constituée de 1 ?\n",
    "3. Vérifier sur les 5 premières données que le jeux de données `DIAGONAL` est tel que la conditon précédente est vérifiée si et seulement si `Y=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponses*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données d'apprentissage et données de validation\n",
    "\n",
    "Le jeu de données est séparé 2 :\n",
    "- Deux tiers des données sont utilisées pour l'apprentissage du réseau de neurones\n",
    "- Le troisième tiers des données est mis à l'écart et sera utilisé pour évaluer la performance du réseau sur ces données (sur lesquelles il n'aura pas appris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(DIAGONAL) # Nombre de données\n",
    "n=int(2*N/3) # Deux tiers du nombres de données \n",
    "X=DIAGONAL.drop(['Y'],axis=1)[0:n] # Données d'apprentissage X\n",
    "Y=DIAGONAL['Y'][0:n] # Données d'apprentissage Y\n",
    "X.insert(loc = 0, column = 'X0',value = np.ones(n,dtype = int)) # On ajoute une colonne de 1 pour b\n",
    "Xvalid=DIAGONAL.drop(['Y'],axis=1)[n+1:N] # Données de validation X\n",
    "Yvalid=DIAGONAL['Y'][n+1:N] # Données de validation Y\n",
    "nvalid=len(Xvalid)\n",
    "Xvalid.insert(loc = 0, column = 'X0',value = np.ones(nvalid,dtype=int)) # On ajoute une colonne de 1 pour b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "Sachant que `DIAGONAL` contient 300 données $(X_i,Y_i)$, sur combien de données le réseau va-t-il apprendre ? Sur combien de données la performance du réseau va-t-elle être évaluée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponses*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau à 1 couche cachée de 2 neurones\n",
    "On approxime $X\\mapsto Y$ par la fonction $R_{\\mathcal{W}}$, où $\\mathcal{W}$ désigne l'ensemble des paramètres $b$, $w_1$, $w_2$, $B=\\begin{pmatrix}b_1\\\\b_2\\end{pmatrix}$ et $W=\\begin{pmatrix}W_1\\\\W_2\\end{pmatrix}=\\begin{pmatrix}w_{11}&w_{12}&\\ldots&w_{19}\\\\w_{21}&w_{22}&\\ldots&w_{29}\\end{pmatrix}$, définie par : $$R_{\\mathcal{W}}:X\\mapsto \\sigma\\left(b+\\begin{pmatrix}w_1&w_2\\end{pmatrix}\\cdot H(B+W\\cdot X)\\right),$$ où\n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$ est la fonction sigmoïd, et $$H=\\begin{pmatrix}h_1(X)\\\\h_2(X)\\end{pmatrix}=\\begin{pmatrix}\\sigma\\left(b_1+\\begin{pmatrix}w_{11}&\\ldots&w_{19}\\end{pmatrix}\\cdot X\\right)\\\\\\sigma\\left(b_2+\\begin{pmatrix}w_{21}&\\ldots&w_{29}\\end{pmatrix}\\cdot X\\right)\\end{pmatrix}$$ est la couche cachée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "1. Combien de paramètres la fonction $R_{\\mathcal{W}}$ possède-t-elle ?\n",
    "2. Représenter le réseau de neurones associé à $R_{\\mathcal{W}}$.\n",
    "3. Pourquoi parle-t-on d'un réseau à *deux* neurones ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponses*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rétropropagation du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres $\\mathcal{W}$ sont déterminés en minimisant la fonction :\n",
    "$$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (R_{\\mathcal{W}}(X_j)-Y_j)^2$$\n",
    "où la somme est calculée sur les données d'apprentissage.\n",
    "\n",
    "On réécrit $$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (\\sigma(s_j)-Y_j)^2$$\n",
    "où $$s_j=b+W\\cdot H_j,$$\n",
    "avec $$H_j=\\begin{pmatrix}\\sigma(h_{1j})\\\\ \\sigma(h_{2j})\\end{pmatrix}$$\n",
    "où $$h_{ij}=b_i+W_i\\cdot X_j.$$\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "On rappelle la propriété $\\sigma'(x)=\\sigma(x)\\times (1-\\sigma(x))$.\n",
    "\n",
    "1. À partir de $$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (\\sigma(\\underbrace{b+W\\cdot H_j}_{s_j})-Y_j)^2$$ établir les dérivées suivantes :\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial b}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j))\\times1$\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial w_i}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j))\\sigma(h_{ij})$\n",
    "\n",
    "2. À partir de $$f(\\mathcal{W})=\\frac{1}{2}\\sum\\limits_{j} (\\sigma(\\underbrace{b+w_1\\sigma(\\underbrace{b_1+\\sum\\limits_{k=1..9} w_{1k}x_{kj}}_{h_{1j}})+w_2\\sigma(\\underbrace{b_2+\\sum\\limits_{k=1..9} w_{2k}x_{kj}}_{h_{2j}})}_{s_j})-Y_j)^2$$ établir les dérivées suivantes :\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial b_i}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j)w_i\\sigma(h_{ij})(1-\\sigma(h_{ij}))\\times 1$\n",
    "    - $\\frac{\\partial f(\\mathcal{W})}{\\partial w_{ik}}=\\sum\\limits_{j} (\\sigma(s_j)-Y_j)\\sigma(s_j)(1-\\sigma(s_j))w_i\\sigma(h_{ij})(1-\\sigma(h_{ij}))x_{kj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponses*\n",
    "\n",
    "Sur papier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction sigmoïde\n",
    "def sigma(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Calcul du gradient\n",
    "def gradient(W): #W=[[b,w1,w2],[b1,w11,w12,...,w19],[b2,w21,...,w29]]\n",
    "    H1=[sigma(np.dot(W[1],X.iloc[j])) for j in range(n)] # liste des sigma(h1j)\n",
    "    H2=[sigma(np.dot(W[2],X.iloc[j])) for j in range(n)] # liste des sigma(h2j)\n",
    "    S=[sigma(W[0][0]+W[0][1]*H1[j]+W[0][2]*H2[j]) for j in range(n)] # liste des sigma(sj)\n",
    "    # Dérivées partielles :\n",
    "    db=np.sum([(S[j]-Y.iloc[j])*S[j]*(1-S[j]) for j in range(n)])\n",
    "    dw1=np.sum([(S[j]-Y.iloc[j])*S[j]*(1-S[j])*H1[j] for j in range(n)])\n",
    "    dw2=np.sum([(S[j]-Y.iloc[j])*S[j]*(1-S[j])*H2[j] for j in range(n)])\n",
    "    db1=np.sum([(S[j]-Y.iloc[j])*S[j]*(1-S[j])*H1[j]*(1-H1[j]) for j in range(n)])\n",
    "    db2=np.sum([(S[j]-Y.iloc[j])*S[j]*(1-S[j])*H2[j]*(1-H2[j]) for j in range(n)])\n",
    "    dW1=[0,0,0,0,0,0,0,0,0]\n",
    "    dW2=[0,0,0,0,0,0,0,0,0]\n",
    "    for k in range(9):\n",
    "        dW1[k]=np.sum([(S[j]-Y.iloc[j])*S[j]*(1-S[j])*H1[j]*(1-H1[j])*X.iloc[j][k] for j in range(n)])\n",
    "        dW2[k]=np.sum([(S[j]-Y.iloc[j])*S[j]*(1-S[j])*H2[j]*(1-H2[j])*X.iloc[j][k] for j in range(n)])\n",
    "    return [[db,dw1,dw2],[db1]+dW1,[db2]+dW2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercice***\n",
    "\n",
    "1. Calculer (dans la cellule ci-dessous) le gradient de $f$ pour des paramètres tous nuls : $\\mathcal{W}_0=(0,\\ldots,0)$.\n",
    "2. En déduire les coordonnées du point $\\mathcal{W}_1$ après une première itération de la descente de gradient pour un pas de $\\tau=10$.\n",
    "3. Calculer le gradient en $\\mathcal{W}_1$. Que remarquez vous ? Comment l'expliquer ?\n",
    "4. Est-ce judicieux de partir de $\\mathcal{W}_0$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculs :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponses*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithme de descente\n",
    "def descente(W,tau=1,tolerance=1e-3,Nbiterations=10):\n",
    "    for i in range(Nbiterations):\n",
    "        g = gradient(W)\n",
    "        normg = g[0][0]**2+g[0][1]**2+g[0][2]**2\n",
    "        +np.sum([g[1][k]**2 for k in range(10)])\n",
    "        +np.sum([g[2][k]**2 for k in range(10)])\n",
    "        print(normg) # On affiche la norme du gradient pour visualiser la descente\n",
    "        if normg< tolerance:\n",
    "            print('L\\'algorithme a convergé.\\n Solution atteinte:\\n W=',W,'\\n Norme du gradient:',normg)\n",
    "            return W\n",
    "        W[0][0]=W[0][0]-tau*g[0][0]\n",
    "        W[0][1]=W[0][1]-tau*g[0][1]\n",
    "        W[0][2]=W[0][2]-tau*g[0][2]\n",
    "        for j in range(10):\n",
    "            W[1][j]=W[1][j]-tau*g[1][j]\n",
    "            W[2][j]=W[2][j]-tau*g[2][j]\n",
    "    print('L\\'algorithme n\\'a pas convergé.\\n Solution atteinte:\\n W=',W,'\\n Norme du gradient:',normg)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercice***\n",
    "\n",
    "Identifier la monotonie de l'algorithme sur les 10 premières itération, à partir de \n",
    "\n",
    "`W=[[1,2,3],[4,5,6,7,8,9,10,11,12,13],[13,12,11,10,9,8,7,6,5,4]]`\n",
    "\n",
    "pour un pas de :\n",
    "\n",
    "$\\tau=1$, $\\tau=10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187.04341999187955\n",
      "187.04341999187875\n",
      "187.0434199918783\n",
      "187.04341999187747\n",
      "187.04341999187676\n",
      "187.04341999187614\n",
      "187.04341999187537\n",
      "187.0434199918747\n",
      "187.0434199918741\n",
      "187.04341999187326\n",
      "L'algorithme n'a pas convergé.\n",
      " Solution atteinte:\n",
      " W= [[-7.999999999999934e-15, -7.843577627329173e-15, -7.843577627329173e-15], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]] \n",
      " Norme du gradient: 187.04341999187326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-7.999999999999934e-15, -7.843577627329173e-15, -7.843577627329173e-15],\n",
       " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W=[[0,0,0],[1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1]]\n",
    "descente(W,tau=1e-16,tolerance=1e-6,Nbiterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(W,X):\n",
    "    return sigma(W[0][0]+W[0][1]*sigma(np.dot(W[1],X))+W[0][1]*sigma(np.dot(W[2],X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'erreurs sur les données de validation : 11.0\n"
     ]
    }
   ],
   "source": [
    "print('Nombre d\\'erreurs sur les données de validation :',np.sum(\\\n",
    "             [np.abs(round(prediction(W,Xvalid.iloc[i]))-Yvalid.iloc[i])\\\n",
    "              for i in range(len(Xvalid)-1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "On considère les paramètres :\n",
    "\n",
    "`W= [[9.88490731988063, -21.978512228107505, -17.916264438553515], [16.24386006076292, -3.3023394159857937, 0.24495692674969732, -7.396212617646716, -3.593451718087197, -11.160218572484126, 3.377878093346306, -0.18551085358790684, 3.6581958544686723, -7.063699791645382], [7.070278747774737, -5.443080663419691, -3.495868955617516, -0.4833459413778877, 0.640016023480778, -0.4530535245792459, -2.5643255163830485, -4.5732183345557385, -5.341507777305012, 0.4114649638794456]]`\n",
    "    \n",
    "Calculer la sortie du réseau de neurones pour une valeur $X$ possèdant une diagonale de $1$ et pour une valeur de $X$ ne possédant pas une diagonale de $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(2,), max_iter=100000,\n",
       "              solver='lbfgs', tol=1e-05)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "algo = MLPClassifier(\\\n",
    "    activation='logistic',\\\n",
    "    solver='lbfgs',\\\n",
    "    shuffle=True,\\\n",
    "    hidden_layer_sizes=(2,),\\\n",
    "    max_iter=100000,\\\n",
    "    tol=1e-5)\n",
    "algo.fit(X.drop(['X0'],axis=1),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b1,b2],[b] :\n",
      "  [array([16.42025076,  5.20972733]), array([9.92372778])] \n",
      "[[w11,w21],[w12,w22]],[w1,w2] :\n",
      "  [array([[ -0.5920726 ,  -9.17818546],\n",
      "       [ -0.46783119,  -0.89718582],\n",
      "       [ -5.21312016,  -3.90961843],\n",
      "       [ -2.23348712,   0.94438838],\n",
      "       [-10.91563272,  -0.1549015 ],\n",
      "       [  0.86375386,  -0.40899946],\n",
      "       [ -1.89036384,  -3.215415  ],\n",
      "       [  1.56834536,  -2.29057482],\n",
      "       [ -7.04240137,   2.11995034]]), array([[-20.83355396],\n",
      "       [-18.42182879]])] \n",
      "Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('[b1,b2],[b] :\\n ',algo.intercepts_,\\\n",
    "      '\\n[[w11,w21],[w12,w22]],[w1,w2] :\\n ',algo.coefs_,\\\n",
    "      '\\nScore : ',algo.score(X.drop(['X0'],axis=1),Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=[[algo.intercepts_[1][0]]+[algo.coefs_[1][0][0]]+[algo.coefs_[1][1][0]],\\\n",
    "[algo.intercepts_[0][0]]+[algo.coefs_[0][k][0] for k in range(9)],\\\n",
    "[algo.intercepts_[0][1]]+[algo.coefs_[0][k][1] for k in range(9)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb d'erreurs : 4\n",
      "[ [0, 1, 0, 1, 0, 1, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 1, 1, 0, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 0, 0, 0, 1, 0, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 1, 1, 0, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 0, 1, 0, 1, 1, 0] ] -> [0] ... on aimerait : 1\n",
      "[ [0, 1, 1, 0, 0, 0, 1, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 0, 1, 1, 1, 1, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 0, 0, 0, 0, 0, 1, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 1, 1, 1, 1, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 1, 0, 0, 1, 0, 1, 1, 1] ] -> [1] ... on aimerait : 1\n",
      "[ [1, 0, 1, 0, 0, 1, 1, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 0, 0, 0, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 1, 1, 1, 1, 0, 1, 1, 1] ] -> [1] ... on aimerait : 1\n",
      "[ [0, 0, 1, 1, 1, 1, 1, 1, 0] ] -> [1] ... on aimerait : 1\n",
      "[ [0, 0, 0, 1, 0, 1, 1, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 0, 0, 0, 1, 0, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 1, 0, 1, 1, 1, 0, 1] ] -> [1] ... on aimerait : 1\n",
      "[ [0, 1, 0, 1, 0, 1, 0, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 1, 0, 1, 0, 0, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 0, 0, 0, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 0, 0, 1, 0, 0, 0, 1] ] -> [1] ... on aimerait : 1\n",
      "[ [1, 1, 0, 1, 1, 0, 1, 1, 1] ] -> [1] ... on aimerait : 1\n",
      "[ [0, 1, 0, 1, 1, 0, 1, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 1, 0, 1, 0, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 1, 1, 1, 1, 0, 0, 1, 1] ] -> [1] ... on aimerait : 1\n",
      "[ [1, 0, 1, 0, 1, 1, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 1, 1, 1, 0, 1, 1, 0, 1] ] -> [1] ... on aimerait : 0\n",
      "[ [1, 1, 1, 1, 0, 1, 1, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 0, 1, 1, 0, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 0, 0, 0, 1, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 1, 0, 0, 1, 0, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 0, 0, 0, 0, 1, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 0, 0, 1, 1, 1, 1, 1] ] -> [1] ... on aimerait : 1\n",
      "[ [0, 0, 0, 1, 1, 1, 1, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 0, 1, 0, 0, 0, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 1, 1, 1, 0, 0, 1, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 1, 0, 0, 1, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 1, 1, 0, 0, 1, 1, 1, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 1, 1, 1, 0, 1, 1, 0] ] -> [1] ... on aimerait : 1\n",
      "[ [1, 1, 0, 0, 0, 0, 1, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 0, 0, 0, 0, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 0, 1, 1, 0, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 0, 0, 0, 1, 0, 1, 1] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 1, 1, 1, 1, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 0, 1, 1, 1, 1, 1, 0, 1] ] -> [0] ... on aimerait : 1\n",
      "[ [1, 1, 1, 1, 1, 0, 0, 0, 0] ] -> [1] ... on aimerait : 0\n",
      "[ [0, 1, 1, 1, 0, 1, 1, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 0, 1, 0, 1, 0, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [0, 1, 0, 1, 1, 1, 1, 1, 0] ] -> [0] ... on aimerait : 0\n",
      "[ [1, 0, 1, 0, 0, 1, 0, 1, 1] ] -> [0] ... on aimerait : 0\n"
     ]
    }
   ],
   "source": [
    "print('Nb d\\'erreurs :',np.sum(\\\n",
    "             [np.abs(algo.predict([Xvalid.iloc[i]])-Yvalid.iloc[i])\\\n",
    "              for i in range(len(Xvalid))]))\n",
    "for i in range(len(Xvalid)):\n",
    "    print('[',[Xvalid.iloc[i][k] for k in range(d)],']',\\\n",
    "          '->',algo.predict([Xvalid.iloc[i]]),\\\n",
    "          '... on aimerait :',Yvalid.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilités\n",
    "\n",
    "predict_probas donne la probabilité d'être de la première classe (O) et la probabilité d'être de la deuxième classe (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 1, 0, 1, 0] -> [1.00000000e+00 1.02622777e-12] ... Classe : 0\n",
      "[0, 0, 1, 1, 1, 1, 0, 0, 0] -> [9.99964351e-01 3.56488060e-05] ... Classe : 0\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 1] -> [1.00000000e+00 2.28703049e-13] ... Classe : 0\n",
      "[0, 0, 1, 1, 1, 1, 0, 0, 1] -> [9.99623908e-01 3.76091650e-04] ... Classe : 0\n",
      "[0, 0, 1, 0, 1, 0, 1, 1, 0] -> [0.94414689 0.05585311] ... Classe : 1\n",
      "[0, 1, 1, 0, 0, 0, 1, 0, 0] -> [9.99995776e-01 4.22415291e-06] ... Classe : 0\n",
      "[0, 0, 0, 1, 1, 1, 1, 0, 1] -> [9.99751129e-01 2.48870568e-04] ... Classe : 0\n",
      "[0, 1, 0, 0, 0, 0, 0, 1, 1] -> [1.0000000e+00 3.0374525e-13] ... Classe : 0\n",
      "[0, 1, 1, 1, 1, 1, 0, 1, 0] -> [0.98481618 0.01518382] ... Classe : 0\n",
      "[1, 1, 0, 0, 1, 0, 1, 1, 1] -> [2.43321191e-04 9.99756679e-01] ... Classe : 1\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 1] -> [9.99920191e-01 7.98094672e-05] ... Classe : 0\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0] -> [1.00000000e+00 5.42572496e-13] ... Classe : 0\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 1] -> [4.59166821e-05 9.99954083e-01] ... Classe : 1\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 0] -> [0.02197994 0.97802006] ... Classe : 1\n",
      "[0, 0, 0, 1, 0, 1, 1, 0, 0] -> [1.00000000e+00 7.01554273e-13] ... Classe : 0\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 0] -> [1.00000000e+00 3.21599663e-13] ... Classe : 0\n",
      "[0, 1, 1, 0, 1, 1, 1, 0, 1] -> [0.0014846 0.9985154] ... Classe : 1\n",
      "[0, 1, 0, 1, 0, 1, 0, 0, 0] -> [1.00000000e+00 2.56485197e-13] ... Classe : 0\n",
      "[1, 1, 0, 1, 0, 0, 0, 1, 0] -> [9.99982809e-01 1.71914145e-05] ... Classe : 0\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 1] -> [1.00000000e+00 1.84352829e-11] ... Classe : 0\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 1] -> [0.00528953 0.99471047] ... Classe : 1\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 1] -> [5.28494035e-05 9.99947151e-01] ... Classe : 1\n",
      "[0, 1, 0, 1, 1, 0, 1, 0, 1] -> [9.99636890e-01 3.63110328e-04] ... Classe : 0\n",
      "[0, 1, 1, 0, 1, 0, 0, 1, 0] -> [9.99904022e-01 9.59778898e-05] ... Classe : 0\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1] -> [4.62940773e-05 9.99953706e-01] ... Classe : 1\n",
      "[1, 0, 1, 0, 1, 1, 0, 1, 0] -> [9.99806540e-01 1.93459864e-04] ... Classe : 0\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1] -> [0.13730567 0.86269433] ... Classe : 0\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 0] -> [9.99981330e-01 1.86699335e-05] ... Classe : 0\n",
      "[1, 0, 0, 1, 1, 0, 0, 1, 0] -> [9.99974547e-01 2.54534304e-05] ... Classe : 0\n",
      "[1, 0, 0, 0, 0, 1, 0, 1, 0] -> [9.99982412e-01 1.75882751e-05] ... Classe : 0\n",
      "[0, 1, 1, 0, 0, 1, 0, 0, 1] -> [1.00000000e+00 1.45493979e-12] ... Classe : 0\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0] -> [9.99982350e-01 1.76499489e-05] ... Classe : 0\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 1] -> [0.03100925 0.96899075] ... Classe : 1\n",
      "[0, 0, 0, 1, 1, 1, 1, 0, 1] -> [9.99751129e-01 2.48870568e-04] ... Classe : 0\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0] -> [1.00000000e+00 2.30276154e-13] ... Classe : 0\n",
      "[0, 1, 1, 1, 1, 0, 0, 1, 1] -> [0.96644107 0.03355893] ... Classe : 0\n",
      "[0, 0, 1, 1, 1, 0, 0, 1, 1] -> [0.99806427 0.00193573] ... Classe : 0\n",
      "[1, 1, 1, 0, 0, 1, 1, 1, 1] -> [9.99974373e-01 2.56268657e-05] ... Classe : 0\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 0] -> [9.39357796e-05 9.99906064e-01] ... Classe : 1\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0] -> [9.99981903e-01 1.80968467e-05] ... Classe : 0\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0] -> [1.00000000e+00 5.42572496e-13] ... Classe : 0\n",
      "[0, 0, 1, 1, 0, 1, 1, 0, 1] -> [9.99999995e-01 4.55745784e-09] ... Classe : 0\n",
      "[0, 1, 0, 0, 0, 1, 0, 1, 1] -> [1.000000e+00 3.973636e-13] ... Classe : 0\n",
      "[0, 1, 1, 1, 1, 1, 0, 1, 0] -> [0.98481618 0.01518382] ... Classe : 0\n",
      "[0, 0, 1, 1, 1, 1, 1, 0, 1] -> [0.88428093 0.11571907] ... Classe : 1\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0] -> [6.45233505e-05 9.99935477e-01] ... Classe : 0\n",
      "[0, 1, 1, 1, 0, 1, 1, 1, 0] -> [9.99984839e-01 1.51612386e-05] ... Classe : 0\n",
      "[1, 0, 0, 1, 0, 1, 0, 1, 0] -> [9.99983292e-01 1.67082854e-05] ... Classe : 0\n",
      "[0, 1, 0, 1, 1, 1, 1, 1, 0] -> [9.9999948e-01 5.2026780e-07] ... Classe : 0\n",
      "[1, 0, 1, 0, 0, 1, 0, 1, 1] -> [9.99981045e-01 1.89546245e-05] ... Classe : 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Xverif)):\n",
    "    print([Xverif.iloc[i][k] for k in range(d)],'->',algo.predict_proba([Xverif.iloc[i]])[0],'... Classe :',Yverif.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def courbes_de_niveaux(fct, x1_min=-5, x2_min=-5, x1_max=5, x2_max=5):\n",
    "    x1_values = np.linspace(x1_min, x1_max,100)\n",
    "    x2_values = np.linspace(x2_min, x2_max,100)\n",
    "    fct_values = np.array([[fct(x1,x2) for x1 in x1_values] for x2 in x2_values])    \n",
    "    plt.contour(x1_values, x2_values, fct_values, 40)\n",
    "    plt.xlim((x1_min, x1_max))\n",
    "    plt.ylim((x2_min, x2_max))\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'courbes_de_niveaux' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-129db4f29d3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Composante 1 de la couche cachée $h_1(X)$\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mcourbes_de_niveaux\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Composante 2 de la couche cachée $h_2(X)$\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'courbes_de_niveaux' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def H1(x1,x2):\n",
    "    return sigmoid(algo.intercepts_[0][0]+algo.coefs_[0][0][0]*x1+algo.coefs_[0][1][0]*x2)\n",
    "def H2(x1,x2):\n",
    "    return sigmoid(algo.intercepts_[0][1]+algo.coefs_[0][0][1]*x1+algo.coefs_[0][1][1]*x2)\n",
    "def R(h1,h2):\n",
    "    return sigmoid(algo.intercepts_[1][0]+algo.coefs_[1][0][0]*h1+algo.coefs_[1][1][0]*h2)\n",
    "def XtoR(x1,x2):\n",
    "    return R(H1(x1,x2),H2(x1,x2)) \n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Composante 1 de la couche cachée $h_1(X)$\")\n",
    "courbes_de_niveaux(H1,0,0,1,1)\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Composante 2 de la couche cachée $h_2(X)$\")\n",
    "courbes_de_niveaux(H2,0,0,1,1)\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Sortie de la couche cachée\")\n",
    "courbes_de_niveaux(R,0,0,1,1)\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"de X à la sortie\")\n",
    "courbes_de_niveaux(XtoR,0,0,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autres tentatives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 , 1 ] -> 0.0002631973630932956 ...on aimerait : 0\n",
      "[ 0 , 0 ] -> 0.0002631973630932956 ...on aimerait : 0\n",
      "[ 0 , 1 ] -> 0.7306388288867955 ...on aimerait : 1\n",
      "[ 1 , 0 ] -> 0.730638828886796 ...on aimerait : 1\n"
     ]
    }
   ],
   "source": [
    "B1=[ 1,-1]\n",
    "B2=[1]\n",
    "V1=[[-10,10],[-10,10]]\n",
    "V2=[[-20],[20]]\n",
    "for i in range(n):\n",
    "    print('[',X.iloc[i][0],',',X.iloc[i][1],']','->',sigmoid(B2[0]\\\n",
    "                                                             +V2[0][0]*sigmoid(B1[0]+V1[0][0]*X.iloc[i][0]+V1[0][1]*X.iloc[i][1])\\\n",
    "                                                             +V2[1][0]*sigmoid(B1[1]+V1[1][0]*X.iloc[i][0]+V1[1][1]*X.iloc[i][1]))\\\n",
    "          ,'...on aimerait :',Y.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représentation graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([algo.predict([X.iloc[i]])[0]+0*np.random.randn(1)/10 for i in range(n)]\\\n",
    "            ,[Y.iloc[i]+0*np.random.randn(1)/10 for i in range(n)]\\\n",
    "            ,alpha=0.1)\n",
    "plt.xlabel('$\\sigma(b+W\\cdot X[i])$')\n",
    "plt.ylabel('$Y[i]$')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur moyenne : 0.0 (score :  1.0 ) \n",
      " Vrai positifs : 2 \n",
      " Faux positifs : 0 \n",
      " Vrai négatifs : 2 \n",
      " Faux négatifs : 0\n"
     ]
    }
   ],
   "source": [
    "maskv1=[Y.iloc[i]==1 for i in range(n)]\n",
    "maskv0=[Y.iloc[i]==0 for i in range(n)]\n",
    "\n",
    "# Prédictions\n",
    "maskp1=[algo.predict([X.iloc[i]])[0]>0.5 for i in range(n)]\n",
    "maskp0=[algo.predict([X.iloc[i]])[0]<=0.5 for i in range(n)]\n",
    "\n",
    "# Erreurs\n",
    "# Y=1 mais sigma(b+XW)<0.5 (Faux négatifs)\n",
    "maske1=[(maskv1[i]==True and maskp1[i]==False) for i in range(len(maskv1))]\n",
    "# Y=0 mais sigma(b+XW)>0.5 (Faux positifs)\n",
    "maske0=[(maskv0[i]==True and maskp0[i]==False) for i in range(len(maskv0))]\n",
    "# Y=1 et sigma(b+XW)>0.5 (Vrais positifs)\n",
    "maskok1=[(maskv1[i]==True and maskp1[i]==True) for i in range(len(maskv1))]\n",
    "# Y=0 et sigma(b+XW)<0.5 (Vrais négatifs)\n",
    "maskok0=[(maskv0[i]==True and maskp0[i]==True) for i in range(len(maskv0))]\n",
    "print(\"Erreur moyenne :\",(np.count_nonzero(maske0)+np.count_nonzero(maske1))/n\\\n",
    "     ,'(score : ',1-(np.count_nonzero(maske0)+np.count_nonzero(maske1))/n,')'\\\n",
    "     ,'\\n Vrai positifs :',np.count_nonzero(maskok1)\n",
    "     ,'\\n Faux positifs :',np.count_nonzero(maske0)\\\n",
    "     ,'\\n Vrai négatifs :',np.count_nonzero(maskok0)\\\n",
    "     ,'\\n Faux négatifs :',np.count_nonzero(maske1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL5iJTlZCmM9764vTsZljv",
   "collapsed_sections": [],
   "name": "descente-deux-variables.ipynb",
   "provenance": [
    {
     "file_id": "164i4yxW6Yks9BXBhzNAJHUMyX1UBjEp3",
     "timestamp": 1606828072802
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
